{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Machine learning (ML) is the study of computer algorithms that improve automatically through experience.  Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so. It is seen as a subset of artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "Supervised learning is the machine learning task of learning a function that maps an input $x$ to an output $y$ based on examples input-output pairs $(x, y)$. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called target value). A supervised learning algorithm analyzes the training data ($(x_1,y_1),\\,(x_2,y_2),\\, \\dots,\\,(x_N,y_N)$) and produces an inferred function $g$, which can be used for mapping new examples. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Learning problem\n",
    "\n",
    "These are the components of the learning problem: \n",
    "\n",
    "* Input: $x$\n",
    "\n",
    "* Output: $y$\n",
    "\n",
    "* Target function: $f : X \\to Y $\n",
    "\n",
    "* Training data: $(x_1,y_1),\\,(x_2,y_2),\\, \\dots,\\,(x_N,y_N)$\n",
    "\n",
    "* Hypothesis: $g : X \\to Y $\n",
    "\n",
    "In a simple way, we can say that $y = f(x)$ for every pair in the data, where $f$ is the target function. The problem is that $f$ is unknown, that is why we use machine learning algorithms to build a mathematical model (function $g$) that approximates unknown function $f$.\n",
    "\n",
    "We use the data to adquire the behavior of the function $f$. We prove a lot of different models until we get the best model (we will call the final model $g$) that better fit the data (approximates $f$).\n",
    "\n",
    "To find the best model among the others, first we need to measure how a model fits the data (the error between true outputs $y$ and estimated outputs $\\hat {y}$) and then minimize this error in order to find $g$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Solution of the learning problem\n",
    "\n",
    "These are the components we have to design to solve the problem of learning.\n",
    "\n",
    "* They Hypothesis Set $\\mathcal{H}, \\quad g \\in \\mathcal{H}$\n",
    "\n",
    "* The Learning Algorithm $\\mathcal{A}$\n",
    "\n",
    "Together, they are referred to as the learning model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- The Learning Diagram\n",
    "\n",
    "So far we have seen all the concepts in a technical way. From now on we are going to see them more theoretically. This diagram including all the components involved in supervised learning.<br><br>\n",
    "\n",
    "<img src=\"Images/Image2.png\" width =\"450\" height=450><br>\n",
    "\n",
    "We will define every component of the diagram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**3.1.- Probability distribution**</font>\n",
    "\n",
    "Let's say $X$ is a random variable with probability distribution $P(X)$. Input values $x$ are sampled from $P(X)$.\n",
    "\n",
    "The input distribution $P(x)$ quantifies relative importance of $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**3.2.- Unknown Target distribution**</font>\n",
    "\n",
    "\n",
    "In reality our data have noisy targets:\n",
    "\n",
    "$$\\text{Noisy target} = \\text{Deterministic target} + \\text{Noise}$$\n",
    "\n",
    "$\\text{Noisy target}$ $=$ $y$\n",
    "\n",
    "$\\text{Deterministic target}$ $=$ $f(x) = E(y \\mid x)$\n",
    "\n",
    "$\\text{Noise}$ = $\\epsilon$\n",
    "\n",
    "$$y = f(x) + \\epsilon$$\n",
    "\n",
    "$$y = f(x) + \\epsilon = P(y\\mid x)$$<br>\n",
    "\n",
    "Instead of $y=f(x)$ we use target distribution $P(y\\mid x)$. The target distribution is what we are trying to learn:\n",
    "\n",
    "$$y= P(y\\mid x)$$\n",
    "\n",
    "\n",
    "Deterministic target is a special case of Noisy target:\n",
    "\n",
    "$$P(y\\mid x) \\; \\text{is zero except for} \\; y=f(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**3.3.- Training examples**</font>\n",
    "\n",
    "Data: $$(x_1,y_1),(x_2,y_2), \\dots,(x_N,y_N)$$ <br>\n",
    "\n",
    "The input values $x$ are sampled from the probability distribution  $P(X)$ and their respective outputs value $y$  are sampled from the probability distribution $P(Y\\mid x)$.\n",
    "\n",
    "We can say that $(x,y)$ is now generated by the joint distribution $P(x,y)$. Given that $P(x,y)=P(x)P(y\\mid x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**3.4.- Hypothesis Set**</font>\n",
    "\n",
    "The hypothesis set $\\mathcal{H}$ is the set of all the possible legal hypothesis. This is the set from which the learning algorithm would determine the best possible (only one) which would best describe the target function. We will use $h$ to denote a hypothesis of $\\mathcal{H}$.\n",
    "\n",
    "**E.g.** \n",
    "\n",
    "A simple hypothesis set: The linear regressor (line model): It has infinite possible legal hypothesis (There are infinite lines)<br><br>\n",
    "\n",
    "<img src=\"Images/Image3.png\" width =\"200\" height=200><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"3\">**3.5.- Learning Algorithm**</font>\n",
    "\n",
    "The learning algorithm $\\mathcal{A}$ determines the best possible hypothesis which would best describe the target function, the learning algorithm minimize the error (cost function) in order to find this hypothesis.\n",
    "\n",
    "**E.g.**\n",
    "\n",
    "A simple learning algorithm: The linear regressor algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**3.6.- Error measure**</font>\n",
    "\n",
    "The learning algorithm uses the error measure to discriminate between all possible hypotheses. Measures how well a hypothesis approximates the objective function. There are two types of error.\n",
    "\n",
    "In-sample error is the error we calculate to find the best hypothesis. We calculate this with the estimated output value $\\hat {y} = h(x)$ and the true output $y$ in every sample of the data. \n",
    "\n",
    "$$E_{in}(h) = \\frac {1}{N} \\sum_{i=1}^{N}e(h(x_i),y_i)$$<br>\n",
    "\n",
    "Out-sample error is a theoretical concept we define to address the goal of learning. We can't calculate the out-sample error because we don't know the true outputs value of unseen data.\n",
    "\n",
    "$$E_{out}(h) = E_{x \\sim X}[e(h(x), f(x))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.1.- Loss Function\n",
    "\n",
    "In supervised machine learning algorithms, we want to minimize the error for each training example $(x,y)$ during the learning process. This is done using some optimization strategies like gradient descent. And this error comes from the loss function. The loss function indicates the way we want to compare the true output $y$ and the estimated output $\\hat {y}$. E.g. Squared error loss is a classic loss function defined as $(y - \\hat {y})^2$.\n",
    "\n",
    "#### 3.6.2.- Cost Function\n",
    "\n",
    "A loss function is for a single training example. It is also sometimes called an error function. A cost function, on the other hand, is the average loss over the entire training dataset. The optimization strategies aim at minimizing the cost function. E.g. Mean squared error (expected value of the squared error) $MSE = \\frac {1}{N} \\sum_{i=1}^{N}(y_i - \\hat {y}_i)^2$\n",
    "\n",
    "#### 3.6.3.- Expected test error\n",
    "\n",
    "We have discussed the idea that training a  model is equivalent to finding values for its parameters that optimize a loss function. It is important to understand, though, that optimizing the performance of the model on the training data is not our goal. What we normally want is, rather, to optimize the performance of the model on new data. This is the expected loss on new data (expected test error or out-sample error).\n",
    "\n",
    "$$E_{out}(h) = E_{x \\sim X}[e(h(x), f(x))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**3.7.- Final hypothesis**</font>\n",
    "\n",
    "The final hypothesis $g \\in \\mathcal{H}$ is the best approximation of the target function $f$.\n",
    "\n",
    "$$g(x) \\approx f(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.- Learning goal\n",
    "\n",
    "We need $g \\approx f$ not only for the training data but for unseen data too, which means $E_{out}(g) \\approx 0$.\n",
    "\n",
    "In order to achieve $E_{out}(g) \\approx 0$, there are two conditions:\n",
    "\n",
    "* $E_{in}(g) \\approx 0 \\quad \\quad \\quad \\quad \\text{(Approximation)}$\n",
    "\n",
    "* $E_{out}(g) \\approx E_{in}(g) \\quad \\quad \\text{(Generalization)}$\n",
    "\n",
    "The two questions of Learning\n",
    "\n",
    "- Can we make $E_{in}(g)$ small enough?\n",
    "\n",
    "- Can we make sure that $E_{out}(g)$ is close enought to $E_{in}(g)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**4.1.- Characterizing the tradeoff**</font>\n",
    "\n",
    "Here we can see how the model complexity affects both errors.\n",
    "\n",
    "* If we increase the model complexity the in-sample error decreases\n",
    "\n",
    "* If we increase the model complexity the difference between out-sample error and in-sample error increases\n",
    "\n",
    "<img src=\"Images/Image1.png\" width =\"350\" height=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**4.2.- Bias - Variance tradeoff**</font>\n",
    "\n",
    "The goal of any supervised machine learning algorithm is to achieve low error (that means low bias and low variance), then the algorithm should achieve good prediction performance.\n",
    "\n",
    "#### Bias of the model\n",
    "\n",
    "Bias is the tendancy of an estimator to pick a model for the data that is not correct. A biased estimator is one that makes incorrect assumptions on the model level about the dataset. For example, suppose that we use a linear regression model on a cubic function. This model will be biased: it will underestimate the true values in the dataset, always, no matter how many points we use.\n",
    "\n",
    "Bias can be expressed mathematically as:\n",
    "\n",
    "$Bias = E_{x \\sim X}[(f(x)-E_{D \\sim D^m}[h_{D}(x)])^2]$\n",
    "\n",
    "This is the extent to which the expected value of the system differs from the expected value of the model.\n",
    "\n",
    "\n",
    "#### Variance of the model\n",
    "\n",
    "Variance is error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random noise in the training data, rather than the intended outputs (overfitting). It can expressed mathematically as:\n",
    "\n",
    "$Variance =  E_{x \\sim X}[E_{D \\sim D^m}[h_{D}(x)^2] - E_{D \\sim D^m}[h_{D}(x)]^2]$\n",
    "\n",
    "Intuitively it can be understood as the extent to which the model moves around its mean.\n",
    "\n",
    "\n",
    "#### The tradeoff\n",
    "\n",
    "The bias–variance tradeoff is the property of a model that the variance of the parameter estimates across samples can be reduced by increasing the bias in the estimated parameters. The bias–variance dilemma or bias–variance problem is the conflict in trying to simultaneously minimize these two sources of error that prevent supervised learning algorithms from generalizing beyond their training set.\n",
    "\n",
    "There is no escaping the relationship between bias and variance in machine learning.\n",
    "\n",
    "* Increasing the bias will decrease the variance.\n",
    "* Increasing the variance will decrease the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.- Bias - Variance Decomposition\n",
    "\n",
    "We will decompose the expected test error into bias and variance. For simplicity, we are going to use the mean squared error (expected value of the squared error loss function)\n",
    "\n",
    "$$\\text{Expected test error} = MSE$$<br>\n",
    "\n",
    "Until now we consider $h(x)$ to be a hypothesis trained on a single data set (This is what we do in reality). But here we are going to consider $h_{D}(x)$ as a hypothesis especifically trained with data set $D$. Theoretically D is sampled from $D^m$\n",
    "\n",
    "$$\\text{Squared error loss function} = e(h_D(x),y) = (y-h_{D}(x))^2$$<br>\n",
    "\n",
    "The $MSE$ is defined as the expected value of the squared error loss function:\n",
    "\n",
    "$$MSE = E_{x \\sim X}[E_{D \\sim D^m}[E_{\\epsilon \\sim \\epsilon^m}[(y-h_{D}(x))^2]]]$$\n",
    "\n",
    "Where $\\epsilon$ is the noise in the target function. We can see that inputs x are sampled from X and noise $\\epsilon$ is sampled from $\\epsilon ^m$<br><br>\n",
    "\n",
    "Given that $MSE = E_{x \\sim X}[E_{D \\sim D^m}[E_{\\epsilon \\sim \\epsilon^m}[(y-h_{D}(x))^2]]]$. We will start with the expectation over $\\epsilon ^m$\n",
    "\n",
    "$$E_{\\epsilon \\sim \\epsilon^m}[(y-h_{D}(x))^2]$$\n",
    "\n",
    "Remember that $y=f(x)+\\epsilon$\n",
    "\n",
    "$E_{\\epsilon \\sim \\epsilon^m}[(y-h_{D}(x))^2]=E_{\\epsilon \\sim \\epsilon^m}[(f(x)+\\epsilon-h_{D}(x))^2]=E_{\\epsilon \\sim \\epsilon^m}[(f(x)-h_{D}(x)+\\epsilon)^2]$\n",
    "\n",
    "$$=E_{\\epsilon \\sim \\epsilon^m}[(f(x)-h_{D}(x)+\\epsilon)^2]$$\n",
    "\n",
    "$$=E_{\\epsilon \\sim \\epsilon^m}[(f(x)-h_{D}(x))^2+\\epsilon^2+2(f(x)-h_{D}(x))(\\epsilon)]$$\n",
    "\n",
    "$$=E_{\\epsilon \\sim \\epsilon^m}[(f(x)-h_{D}(x))^2]+E_{\\epsilon \\sim \\epsilon^m}[\\epsilon^2]+E_{\\epsilon \\sim \\epsilon^m}[2(f(x)-h_{D}(x))(\\epsilon)]$$<br>\n",
    "\n",
    "Since $f(x)$, $h_D(x)$ don't depend on $\\epsilon$, they are treated as constants for this expectation\n",
    "\n",
    "$$=(f(x)-h_{D}(x))^2+E_{\\epsilon \\sim \\epsilon^m}[\\epsilon^2]+2(f(x)-h_{D}(x))E_{\\epsilon \\sim \\epsilon^m}[\\epsilon]$$<br>\n",
    "\n",
    "Considering that the noise distribution has mean equal to 0 ($E_{\\epsilon \\sim \\epsilon^m}[\\epsilon]=0$):\n",
    "\n",
    "$$E_{\\epsilon \\sim \\epsilon^m}[(y-h_{D}(x))^2]=(f(x)-h_{D}(x))^2+E_{\\epsilon \\sim \\epsilon^m}[\\epsilon^2]$$<br>\n",
    "\n",
    "If $E_{\\epsilon \\sim \\epsilon^m}[\\epsilon]=0$, then $Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)=E_{\\epsilon \\sim \\epsilon^m}[\\epsilon^2]-E_{\\epsilon \\sim \\epsilon^m}[\\epsilon]=E_{\\epsilon \\sim \\epsilon^m}[\\epsilon^2]$:\n",
    "\n",
    "$$E_{\\epsilon \\sim \\epsilon^m}[(y-h_{D}(x))^2]=(f(x)-h_{D}(x))^2+Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)$$<br>\n",
    "\n",
    "The first term is called reducible error and the second term is called irreducible error\n",
    "\n",
    "$\\text{Reducible error}=(f(x)-h_{D}(x))^2$\n",
    "\n",
    "$\\text{Irreducible error}=Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)$<br><br>\n",
    "\n",
    "From here on, we will treat $Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)$ as constant for expectations over $D^m$ and $X$. Let's continue decomposing the $MSE$\n",
    "\n",
    "$$MSE = E_{x \\sim X}[E_{D \\sim D^m}[(f(x)-h_{D}(x))^2+Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)]]$$<br>\n",
    "\n",
    "Now, we will focus on the expectation over $D^m$\n",
    "\n",
    "$E_{D \\sim D^m}[(f(x)-h_{D}(x))^2+Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)]=E_{D \\sim D^m}[(f(x)-h_{D}(x))^2]+E_{D \\sim D^m}[Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)]=E_{D \\sim D^m}[(f(x)-h_{D}(x))^2]+Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)$\n",
    "\n",
    "$$E_{D \\sim D^m}[(f(x)-h_{D}(x))^2]$$\n",
    "\n",
    "$$E_{D \\sim D^m}[f(x)^2+h_{D}(x)^2-2f(x)h_{D}(x)]$$\n",
    "\n",
    "$$E_{D \\sim D^m}[f(x)^2]+E_{D \\sim D^m}[h_{D}(x)^2]-E_{D \\sim D^m}[2f(x)h_{D}(x)]$$<br>\n",
    "\n",
    "Since $f(x)$ doesn't depend on $D$, $f(x)$ is treated as constant for this expectation\n",
    "\n",
    "$$f(x)^2+E_{D \\sim D^m}[h_{D}(x)^2]-2f(x)E_{D \\sim D^m}[h_{D}(x)]$$<br>\n",
    "\n",
    "Adding and subtracting $E_{D \\sim D^m}[h_{D}(x)]^2$, and then rearranging terms\n",
    "\n",
    "$$f(x)^2+E_{D \\sim D^m}[h_{D}(x)^2]-2f(x)E_{D \\sim D^m}[h_{D}(x)] + E_{D \\sim D^m}[h_{D}(x)]^2 - E_{D \\sim D^m}[h_{D}(x)]^2$$\n",
    "\n",
    "$$(f(x)-E_{D \\sim D^m}[h_{D}(x)])^2 + E_{D \\sim D^m}[h_{D}(x)^2] - E_{D \\sim D^m}[h_{D}(x)]^2$$<br>\n",
    "\n",
    "This is the bias term for a single x:\n",
    "\n",
    "$bias(x)=(f(x)-E_{D \\sim D^m}[h_{D}(x)])^2$\n",
    "\n",
    "This is the variance term for a single x:\n",
    "\n",
    "$variance(x)=E_{D \\sim D^m}[h_{D}(x)^2] - E_{D \\sim D^m}[h_{D}(x)]^2$<br><br>\n",
    "\n",
    "Finally, averaging over X:\n",
    "\n",
    "$MSE = E_{x \\sim X}[(f(x)-E_{D \\sim D^m}[h_{D}(x)])^2 + E_{D \\sim D^m}[h_{D}(x)^2] - E_{D \\sim D^m}[h_{D}(x)]^2 + Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)]$\n",
    "\n",
    "$MSE = E_{x \\sim X}[(f(x)-E_{D \\sim D^m}[h_{D}(x)])^2] + E_{x \\sim X}[E_{D \\sim D^m}[h_{D}(x)^2] - E_{D \\sim D^m}[h_{D}(x)]^2] + E_{x \\sim X}[Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)]$\n",
    "\n",
    "$MSE = E_{x \\sim X}[(f(x)-E_{D \\sim D^m}[h_{D}(x)])^2] + E_{x \\sim X}[E_{D \\sim D^m}[h_{D}(x)^2] - E_{D \\sim D^m}[h_{D}(x)]^2] + Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)$<br><br>\n",
    "\n",
    "The first term is the bias of the model and the second one is the variance of the model\n",
    "\n",
    "$Bias = E_{x \\sim X}[(f(x)-E_{D \\sim D^m}[h_{D}(x)])^2]$\n",
    "\n",
    "$Variance =  E_{x \\sim X}[E_{D \\sim D^m}[h_{D}(x)^2] - E_{D \\sim D^m}[h_{D}(x)]^2]$<br><br>\n",
    "\n",
    "$$MSE = Bias + Variance + Var_{\\epsilon \\sim \\epsilon^m}(\\epsilon)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real life, we cannot calculate bias & variance. Recap: Bias measures how much the estimator (can be any machine learning algorithm) is wrong with respect to varying samples, and similarly variance measures how much the estimator fluctuate around the expected value of the estimator. To calculate the bias & variance, we need to generate a number of datasets from some known function by adding noise and train a separate model (estimator) using each dataset. Since we don't know neither the above mentioned known function nor the added noise, we cannot do it. In practise, we can only calculate the overall error. In order to combat with bias/variance dilemma, we do cross-validation.\n",
    "\n",
    "Nevertheless, as a framework, bias and variance provide the tools to understand the behavior of machine learning algorithms in the pursuit of predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.- Underfitting and Overfitting\n",
    "\n",
    "<img src=\"Images/Image4.png\" width =\"600\" height=500><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-Underfitting (High bias)**\n",
    "\n",
    "A machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data. Underfitting destroys the accuracy of our machine learning model. Its occurrence simply means that our model or the algorithm does not fit the data well enough.\n",
    "\n",
    "Theoretically, the expected value of the model $E_{D \\sim D^m}[h_{D}(x)]$ fails to approximate the target function $f(x)$.\n",
    "\n",
    "**-Overfitting (High variance)**\n",
    "\n",
    "Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. The problem is that these concepts do not apply to new data and negatively impact the models ability to generalize.\n",
    "\n",
    "Theoretically, there is a lot of fluctuation around the expected value of the estimator $E_{D \\sim D^m}[h_{D}(x)]$. We can see that if we change the training data set $D$, the estimator will change drastically (if we change the points in the graphic, the estimator will overfit these new points and the result will be a estimator that is far away from the first one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More info\n",
    "\n",
    "If you want to dive into the machine learning theory I recommend this [course](http://work.caltech.edu/telecourse.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
